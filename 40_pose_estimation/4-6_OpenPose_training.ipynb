{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.6 学習と検証の実施\n",
    "\n",
    "- 本ファイルでは、OpenPoseの学習と検証の実施を行います。AWSのGPUマシンで計算します。\n",
    "- p2.xlargeで45分ほどかかります。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習目標\n",
    "\n",
    "1.\tOpenPoseの学習を実装できるようになる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 事前準備\n",
    "\n",
    "- これまでの章で実装したクラスと関数をフォルダ「utils」内に用意しています\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パッケージのimport\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期設定\n",
    "# Setup seeds\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader import make_datapath_list, DataTransform, COCOkeypointsDataset\n",
    "\n",
    "# MS COCOのファイルパスリスト作成\n",
    "train_img_list, train_mask_list, val_img_list, val_mask_list, train_meta_list, val_meta_list = make_datapath_list(\n",
    "    rootpath=\"./data/\")\n",
    "\n",
    "# Dataset作成\n",
    "# 本書ではデータ量の問題から、trainをval_listで作成している点に注意\n",
    "train_dataset = COCOkeypointsDataset(\n",
    "    val_img_list, val_mask_list, val_meta_list, phase=\"train\", transform=DataTransform())\n",
    "\n",
    "# 今回は簡易な学習とし検証データは作成しない\n",
    "# val_dataset = CocokeypointsDataset(val_img_list, val_mask_list, val_meta_list, phase=\"val\", transform=DataTransform())\n",
    "\n",
    "# DataLoader作成\n",
    "batch_size = 32\n",
    "batch_size = 16\n",
    "\n",
    "train_dataloader = data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# val_dataloader = data.DataLoader(\n",
    "#    val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 辞書型変数にまとめる\n",
    "# dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
    "dataloaders_dict = {\"train\": train_dataloader, \"val\": None}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ネットワークモデル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.openpose_net import OpenPoseNet\n",
    "net = OpenPoseNet()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 損失関数を定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数の設定\n",
    "class OpenPoseLoss(nn.Module):\n",
    "    \"\"\"OpenPoseの損失関数のクラスです。\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(OpenPoseLoss, self).__init__()\n",
    "\n",
    "    def forward(self, saved_for_loss, heatmap_target, heat_mask, paf_target, paf_mask):\n",
    "        \"\"\"\n",
    "        損失関数の計算。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        saved_for_loss : OpenPoseNetの出力(リスト)\n",
    "\n",
    "        heatmap_target : [num_batch, 19, 46, 46]\n",
    "            正解の部位のアノテーション情報\n",
    "\n",
    "        heatmap_mask : [num_batch, 19, 46, 46]\n",
    "            heatmap画像のmask\n",
    "\n",
    "        paf_target : [num_batch, 38, 46, 46]\n",
    "            正解のPAFのアノテーション情報\n",
    "\n",
    "        paf_mask : [num_batch, 38, 46, 46]\n",
    "            PAF画像のmask\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        loss : テンソル\n",
    "            損失の値\n",
    "        \"\"\"\n",
    "\n",
    "        total_loss = 0\n",
    "        # ステージごとに計算します\n",
    "        for j in range(6):\n",
    "\n",
    "            # PAFsとheatmapsにおいて、マスクされている部分（paf_mask=0など）は無視させる\n",
    "            # PAFs\n",
    "            pred1 = saved_for_loss[2 * j] * paf_mask\n",
    "            gt1 = paf_target.float() * paf_mask\n",
    "\n",
    "            # heatmaps\n",
    "            pred2 = saved_for_loss[2 * j + 1] * heat_mask\n",
    "            gt2 = heatmap_target.float()*heat_mask\n",
    "\n",
    "            total_loss += F.mse_loss(pred1, gt1, reduction='mean') + \\\n",
    "                F.mse_loss(pred2, gt2, reduction='mean')\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "\n",
    "criterion = OpenPoseLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最適化手法を設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=1e-2,\n",
    "                      momentum=0.9,\n",
    "                      weight_decay=0.0001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習を実施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを学習させる関数を作成\n",
    "\n",
    "\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "\n",
    "    # GPUが使えるかを確認\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"使用デバイス：\", device)\n",
    "\n",
    "    # ネットワークをGPUへ\n",
    "    net.to(device)\n",
    "\n",
    "    # ネットワークがある程度固定であれば、高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # 画像の枚数\n",
    "    num_train_imgs = len(dataloaders_dict[\"train\"].dataset)\n",
    "    batch_size = dataloaders_dict[\"train\"].batch_size\n",
    "\n",
    "    # イテレーションカウンタをセット\n",
    "    iteration = 1\n",
    "\n",
    "    # epochのループ\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # 開始時刻を保存\n",
    "        t_epoch_start = time.time()\n",
    "        t_iter_start = time.time()\n",
    "        epoch_train_loss = 0.0  # epochの損失和\n",
    "        epoch_val_loss = 0.0  # epochの損失和\n",
    "\n",
    "        print('-------------')\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-------------')\n",
    "\n",
    "        # epochごとの訓練と検証のループ\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()  # モデルを訓練モードに\n",
    "                optimizer.zero_grad()\n",
    "                print('（train）')\n",
    "\n",
    "            # 今回は検証はスキップ\n",
    "            else:\n",
    "                continue\n",
    "                # net.eval()   # モデルを検証モードに\n",
    "                # print('-------------')\n",
    "                # print('（val）')\n",
    "\n",
    "            # データローダーからminibatchずつ取り出すループ\n",
    "            for imges, heatmap_target, heat_mask, paf_target, paf_mask in dataloaders_dict[phase]:\n",
    "                # ミニバッチがサイズが1だと、バッチノーマライゼーションでエラーになるのでさける\n",
    "                if imges.size()[0] == 1:\n",
    "                    continue\n",
    "\n",
    "                # GPUが使えるならGPUにデータを送る\n",
    "                imges = imges.to(device)\n",
    "                heatmap_target = heatmap_target.to(device)\n",
    "                heat_mask = heat_mask.to(device)\n",
    "                paf_target = paf_target.to(device)\n",
    "                paf_mask = paf_mask.to(device)\n",
    "\n",
    "                # optimizerを初期化\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 順伝搬（forward）計算\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # (out6_1, out6_2)は使わないので _ で代替\n",
    "                    _, saved_for_loss = net(imges)\n",
    "\n",
    "                    loss = criterion(saved_for_loss, heatmap_target,\n",
    "                                     heat_mask, paf_target, paf_mask)\n",
    "                    del saved_for_loss\n",
    "                    # 訓練時はバックプロパゲーション\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                        if (iteration % 10 == 0):  # 10iterに1度、lossを表示\n",
    "                            t_iter_finish = time.time()\n",
    "                            duration = t_iter_finish - t_iter_start\n",
    "                            print('イテレーション {} || Loss: {:.4f} || 10iter: {:.4f} sec.'.format(\n",
    "                                iteration, loss.item()/batch_size, duration))\n",
    "                            t_iter_start = time.time()\n",
    "\n",
    "                        epoch_train_loss += loss.item()\n",
    "                        iteration += 1\n",
    "\n",
    "                    # 検証時\n",
    "                    # else:\n",
    "                        #epoch_val_loss += loss.item()\n",
    "\n",
    "        # epochのphaseごとのlossと正解率\n",
    "        t_epoch_finish = time.time()\n",
    "        print('-------------')\n",
    "        print('epoch {} || Epoch_TRAIN_Loss:{:.4f} ||Epoch_VAL_Loss:{:.4f}'.format(\n",
    "            epoch+1, epoch_train_loss/num_train_imgs, 0))\n",
    "        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
    "        t_epoch_start = time.time()\n",
    "\n",
    "    # 最後のネットワークを保存する\n",
    "    torch.save(net.state_dict(), 'weights/openpose_net_' +\n",
    "               str(epoch+1) + '.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用デバイス： cuda:0\n",
      "-------------\n",
      "Epoch 1/2\n",
      "-------------\n",
      "（train）\n",
      "イテレーション 10 || Loss: 0.0190 || 10iter: 25.3351 sec.\n",
      "イテレーション 20 || Loss: 0.0155 || 10iter: 20.0820 sec.\n",
      "イテレーション 30 || Loss: 0.0138 || 10iter: 19.7297 sec.\n",
      "イテレーション 40 || Loss: 0.0124 || 10iter: 19.1452 sec.\n",
      "イテレーション 50 || Loss: 0.0105 || 10iter: 19.0495 sec.\n",
      "イテレーション 60 || Loss: 0.0084 || 10iter: 19.6817 sec.\n",
      "イテレーション 70 || Loss: 0.0075 || 10iter: 19.7701 sec.\n",
      "イテレーション 80 || Loss: 0.0065 || 10iter: 18.8513 sec.\n",
      "イテレーション 90 || Loss: 0.0057 || 10iter: 18.7665 sec.\n",
      "イテレーション 100 || Loss: 0.0050 || 10iter: 18.6566 sec.\n",
      "イテレーション 110 || Loss: 0.0046 || 10iter: 18.2268 sec.\n",
      "イテレーション 120 || Loss: 0.0039 || 10iter: 17.5010 sec.\n",
      "イテレーション 130 || Loss: 0.0039 || 10iter: 18.6196 sec.\n",
      "イテレーション 140 || Loss: 0.0037 || 10iter: 18.1377 sec.\n",
      "イテレーション 150 || Loss: 0.0029 || 10iter: 17.9112 sec.\n",
      "イテレーション 160 || Loss: 0.0037 || 10iter: 16.8203 sec.\n",
      "イテレーション 170 || Loss: 0.0035 || 10iter: 18.6018 sec.\n",
      "イテレーション 180 || Loss: 0.0030 || 10iter: 17.1619 sec.\n",
      "イテレーション 190 || Loss: 0.0036 || 10iter: 17.3637 sec.\n",
      "イテレーション 200 || Loss: 0.0031 || 10iter: 16.9941 sec.\n",
      "イテレーション 210 || Loss: 0.0028 || 10iter: 17.2581 sec.\n",
      "イテレーション 220 || Loss: 0.0029 || 10iter: 16.8797 sec.\n",
      "イテレーション 230 || Loss: 0.0045 || 10iter: 17.4487 sec.\n",
      "イテレーション 240 || Loss: 0.0024 || 10iter: 17.6010 sec.\n",
      "イテレーション 250 || Loss: 0.0029 || 10iter: 17.2985 sec.\n",
      "イテレーション 260 || Loss: 0.0034 || 10iter: 16.9915 sec.\n",
      "イテレーション 270 || Loss: 0.0036 || 10iter: 16.8980 sec.\n",
      "イテレーション 280 || Loss: 0.0028 || 10iter: 16.7254 sec.\n",
      "イテレーション 290 || Loss: 0.0029 || 10iter: 16.9310 sec.\n",
      "イテレーション 300 || Loss: 0.0026 || 10iter: 17.2985 sec.\n",
      "-------------\n",
      "epoch 1 || Epoch_TRAIN_Loss:0.0058 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  588.1426 sec.\n",
      "-------------\n",
      "Epoch 2/2\n",
      "-------------\n",
      "（train）\n",
      "イテレーション 310 || Loss: 0.0031 || 10iter: 8.3410 sec.\n",
      "イテレーション 320 || Loss: 0.0032 || 10iter: 16.7652 sec.\n",
      "イテレーション 330 || Loss: 0.0027 || 10iter: 16.9714 sec.\n",
      "イテレーション 340 || Loss: 0.0019 || 10iter: 17.1951 sec.\n",
      "イテレーション 350 || Loss: 0.0026 || 10iter: 17.2070 sec.\n",
      "イテレーション 360 || Loss: 0.0026 || 10iter: 17.4563 sec.\n",
      "イテレーション 370 || Loss: 0.0024 || 10iter: 16.9678 sec.\n",
      "イテレーション 380 || Loss: 0.0030 || 10iter: 16.7186 sec.\n",
      "イテレーション 390 || Loss: 0.0026 || 10iter: 16.7764 sec.\n",
      "イテレーション 400 || Loss: 0.0026 || 10iter: 16.7797 sec.\n",
      "イテレーション 410 || Loss: 0.0031 || 10iter: 17.6679 sec.\n",
      "イテレーション 420 || Loss: 0.0027 || 10iter: 16.6885 sec.\n",
      "イテレーション 430 || Loss: 0.0031 || 10iter: 17.6328 sec.\n",
      "イテレーション 440 || Loss: 0.0024 || 10iter: 17.0045 sec.\n",
      "イテレーション 450 || Loss: 0.0030 || 10iter: 17.0057 sec.\n",
      "イテレーション 460 || Loss: 0.0028 || 10iter: 16.1089 sec.\n",
      "イテレーション 470 || Loss: 0.0023 || 10iter: 16.1348 sec.\n",
      "イテレーション 480 || Loss: 0.0021 || 10iter: 16.4620 sec.\n",
      "イテレーション 490 || Loss: 0.0022 || 10iter: 16.5168 sec.\n",
      "イテレーション 500 || Loss: 0.0034 || 10iter: 16.7109 sec.\n",
      "イテレーション 510 || Loss: 0.0032 || 10iter: 16.4041 sec.\n",
      "イテレーション 520 || Loss: 0.0024 || 10iter: 16.3044 sec.\n",
      "イテレーション 530 || Loss: 0.0026 || 10iter: 16.6928 sec.\n",
      "イテレーション 540 || Loss: 0.0029 || 10iter: 17.8398 sec.\n",
      "イテレーション 550 || Loss: 0.0023 || 10iter: 17.4711 sec.\n",
      "イテレーション 560 || Loss: 0.0021 || 10iter: 17.0786 sec.\n",
      "イテレーション 570 || Loss: 0.0023 || 10iter: 17.1939 sec.\n",
      "イテレーション 580 || Loss: 0.0029 || 10iter: 16.3744 sec.\n",
      "イテレーション 590 || Loss: 0.0022 || 10iter: 17.0502 sec.\n",
      "イテレーション 600 || Loss: 0.0028 || 10iter: 17.4725 sec.\n",
      "イテレーション 610 || Loss: 0.0021 || 10iter: 17.6949 sec.\n",
      "-------------\n",
      "epoch 2 || Epoch_TRAIN_Loss:0.0028 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  545.9418 sec.\n"
     ]
    }
   ],
   "source": [
    "# 学習・検証を実行する\n",
    "num_epochs = 2\n",
    "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
